# 为 Graph 服务开启水平自动扩缩容

NebulaGraph Operator 支持使用 NebulaAutoscaler 对象为 Graph 服务配置 [Pod 水平自动扩缩](https://kubernetes.io/zh-cn/docs/tasks/run-application/horizontal-pod-autoscale/) (Horizontal Pod Autoscaling，下文简称为 HPA)，实现基于资源使用情况自动调整 Graph 服务 Pod 的数量。

## 前提条件

已创建{{nebula.name}}集群。具体步骤，参见[创建{{nebula.name}}集群](../4.1.installation/4.1.1.cluster-install.md)。

## 使用限制

仅支持对 Graph 服务开启 HPA。

## 操作步骤

下文将介绍在{{nebula.name}}集群中启用 HPA 的流程。

1. 安装 metrics-server。

  NebulaAutoscaler 基于 K8s 的 HorizontalPodAutoscaler 设计，依赖于 metrics-server 收集的资源指标数据从而实现自动调整 Pod 数量的功能。

  执行以下命令安装最新版本的 metrics-server。
  
  ```bash
  kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
  ```

2. 验证 metrics-server 运行正常。

  metrics-server 暴露了 Metrics API，用来提供关于节点和 Pods 的 CPU 和内存资源使用情况的信息。下面将通过访问 Metrics API 来获取 metrics-server 收集到的资源使用量数据。若成功返回资源使用量数据，则说明 metrics-server 运行正常。

  执行以下命令查看名为`nebula-graphd-1`的 Pod 的资源使用情况：

  ```bash
  kubectl get --raw "/apis/metrics.k8s.io/v1beta1/namespaces/default/pods/nebula-graphd-1" | jq '.'
  ```

  返回示例：

  ```json
  {
    "kind": "PodMetrics",
    "apiVersion": "metrics.k8s.io/v1beta1",
    "metadata": {
      "name": "nebula-graphd-1",
      "namespace": "default",
      "creationTimestamp": "2023-09-27T13:39:54Z",
      "labels": {
        "app.kubernetes.io/cluster": "nebula",
        "app.kubernetes.io/component": "graphd",
        "app.kubernetes.io/managed-by": "nebula-operator",
        "app.kubernetes.io/name": "nebula-graph",
        "controller-revision-hash": "nebula-graphd-56cf5f8b66",
        "statefulset.kubernetes.io/pod-name": "nebula-graphd-1"
      }
    },
    "timestamp": "2023-09-27T13:39:48Z",
    "window": "15.015s",
    "containers": [
      {
        "name": "graphd",
        "usage": {
          "cpu": "323307n",
          "memory": "12644Ki"
        }
      }
    ]
  }
  ```

  执行以下命令查看名为`192-168-8-xx`的节点的资源使用情况：

  ```bash
  kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes/192-168-8-xx" | jq '.'
  ```

  返回示例：

  ```json
  {
    "kind": "NodeMetrics",
    "apiVersion": "metrics.k8s.io/v1beta1",
    "metadata": {
      "name": "192-168-8-xx",
      "creationTimestamp": "2023-09-27T14:00:13Z",
      "labels": {
        "beta.kubernetes.io/arch": "amd64",
        "beta.kubernetes.io/os": "linux",
        "kubernetes.io/arch": "amd64",
        "kubernetes.io/hostname": "192-168-8-xx",
        "kubernetes.io/os": "linux",
        "nebula": "cloud",
        "node-role.kubernetes.io/control-plane": "",
        "node.kubernetes.io/exclude-from-external-load-balancers": ""
      }
    },
    "timestamp": "2023-09-27T14:00:00Z",
    "window": "20.045s",
    "usage": {
      "cpu": "164625163n",
      "memory": "8616740Ki"
    }
  }
  ```

3. 创建 NebulaAutoscaler 对象。

  以下示例定义的 NebulaAutoscaler 对象会基于平均 CPU 使用率，将 Pods 数量维持在 2 到 5 个之间。

  ```yaml
  apiVersion: autoscaling.nebula-graph.io/v1alpha1
  kind: NebulaAutoscaler
  metadata:
    name: nebula-autoscaler
  spec:
    nebulaClusterRef:
      name: nebula
    graphdPolicy:
      minReplicas: 2
      maxReplicas: 5
      metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 50
    pollingPeriod: 30s
  ```

  关键参数的描述如下:

  - `spec.nebulaClusterRef`：该 NebulaAutoscaler 作用的目标集群。
  - `spec.graphdPolicy`：该 NebulaAutoscaler 采用的伸缩策略。该参数的子字段与 K8s 的 HorizontalPodAutoscaler 支持的字段完全兼容。详细字段定义请参考 [API 文档](https://kubernetes.io/zh-cn/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec)。 
  - `spec.pollingPeriod`: NebulaAutoscaler 进行资源使用率检查的时间间隔。

  此外，NebulaAutoscaler 也支持`behavior`参数，用于定义 Pod 数量扩张和收缩时的不同表现，实现更精细化的伸缩控制。

  在使用`behavior`参数前，建议先完全理解其 [API 文档](https://kubernetes.io/zh-cn/docs/reference/kubernetes-api/workload-resources/horizontal-pod-autoscaler-v2/#HorizontalPodAutoscalerSpec)中的字段定义。

  以下示例定义的 NebulaAutoscaler 会在 Pod 数量扩张和收缩时采取不同的行为：

  ```yaml
  apiVersion: autoscaling.nebula-graph.io/v1alpha1
  kind: NebulaAutoscaler
  metadata:
    name: nebula-autoscaler
  spec:
    nebulaClusterRef:
      name: nebula
    graphdPolicy:
      minReplicas: 2
      maxReplicas: 5
      metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 50
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 100
            periodSeconds: 15
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
          - type: Percent
            value: 100
            periodSeconds: 15
          - type: Pods
            value: 4
            periodSeconds: 15
          selectPolicy: Max
    pollingPeriod: 30s
  ```

4. 验证 HPA 效果。

  在执行`kubectl apply`命令创建 NebulaAutoscaler 对象后，可以使用以下方式检查 HPA 的效果。

  执行`kubectl get na`命令检查 NebulaAutoscaler 的配置和状态。

  返回示例：

  ```
  NAME                REFERENCE   MIN-REPLICAS   MAX-REPLICAS   CURRENT-REPLICAS   ACTIVE   ABLETOSCALE   LIMITED   READY   AGE
  nebula-autoscaler   nebula      2              5              2                  True     True          True      True    19h
  ```

  执行`kubectl get nc`命令检查{{nebula.name}}集群的状态。

  返回示例：

  ```
  NAME     READY   GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
  nebula   True    2                2              1               1             3                  3                20h
  ```
